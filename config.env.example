# Database
DATABASE_URL="postgresql://postgres:password@localhost:5433/archiviz"

# Redis
REDIS_URL="redis://localhost:6379"


# OpenAI (for embeddings)
OPENAI_API_KEY="your-openai-api-key-here"

# Amazon Bedrock (AI/LLM integration)
BEDROCK_API_KEY="your-bedrock-api-key"              # Amazon Bedrock API key for authentication
BEDROCK_REGION="us-east-1"                          # AWS region where Bedrock is enabled
BEDROCK_EMBEDDING_MODEL_ID="amazon.titan-embed-text-v1"  # Model ID for code/document embeddings
BEDROCK_GENERATION_MODEL_ID="anthropic.claude-v2"   # Model ID for code generation/explanation/chat

# AWS Credentials (optional if not using IAM roles)
AWS_ACCESS_KEY_ID="your-aws-access-key-id"           # AWS access key for Bedrock API
AWS_SECRET_ACCESS_KEY="your-aws-secret-access-key"   # AWS secret key for Bedrock API

# Bedrock API endpoint (optional, override if needed)
BEDROCK_ENDPOINT="https://bedrock-runtime.us-east-1.amazonaws.com" # Custom endpoint if required

# AI/Embedding Service
EMBEDDING_BATCH_SIZE=100                              # Number of symbols to embed per batch
EMBEDDING_DIMENSIONS=1536                             # Embedding vector size (e.g., Titan/OpenAI Ada)
EMBEDDING_RATE_LIMIT_PER_MIN=1000                     # Max symbols to embed per minute

# Semantic Search & Analysis
SEARCH_RESULT_LIMIT=20                                # Max results to return for semantic search
SEARCH_HISTORY_LIMIT=50                               # Max search queries to store per user
AI_ANALYSIS_TIMEOUT=5                                 # Max seconds for code analysis per file

# pgvector/PostgreSQL (if not using DATABASE_URL)
PGVECTOR_TABLE="embeddings"                          # Table for storing embeddings
PGVECTOR_DIMENSIONS=1536                              # Vector dimensions for pgvector

# App
NEXT_PUBLIC_APP_URL="http://localhost:3000"
